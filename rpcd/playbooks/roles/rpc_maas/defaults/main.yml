---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## MaaS Options
#
# maas_auth_method: Specifies how to authenticate against Rackspace Cloud Monitoring.
#
#   This can be set to one of the following two options:
#     - password: authorization uses the variables set in maas_auth_url, maas_api_key and
#                 maas_username
#     - token: authorization uses the maas_api_url and maas_auth_token key
#
maas_auth_method: password

#
# maas_auth_url: Rackspace Cloud auth URL.
#
maas_auth_url: https://identity.api.rackspacecloud.com/v2.0

#
# maas_tenant_id:  Rackspace Cloud tenant ID (required when maas_auth_method is set to password).
#
maas_tenant_id: SomeTenantID

#
# maas_username: Rackspace Cloud user name (required when maas_auth_method is set to password).
#
maas_username: SomeUserName

#
# maas_username: Rackspace Cloud API key (required when maas_auth_method is set to password).
#
maas_api_key: SomeAPIKey

#
# maas_auth_token: Rackspace Cloud auth token (required when maas_auth_method is set to token).
#
maas_auth_token: some_token

#
# maas_api_url: Cloud Monitoring endpoint (required when maas_auth_method is set to token).
#
maas_api_url: https://monitoring.api.rackspacecloud.com/v1.0/{{ maas_tenant_id }}

#
# maas_notification_plan: The Cloud Monitoring notification plan, which defines who will be
#                         notified, and for what.
#
maas_notification_plan: npManaged

#
# maas_external_ip_address:
#
maas_external_ip_address: "{{ external_vip_address }}"

#
# maas_agent_token: The Cloud Monitoring agent token to configure the agent with.
#
#   By default an agent token is created for each entity. However, you may prefer to use the same
#   agent token for all entities. In that case, specify the agent token here.
#
#maas_agent_token: some_token

#
# maas_target_alias: An alias used for remote checks in the event that a device has multiple
#                    public IP addresses or if there are other issues with the default primary IP
#                    address.
#
#   For remote checks, the entity specified by lb_name in rpc_user_config has a variable that
#   denotes the IP addresses to check against. By default, this is the public0_v4 address. Setting
#   this variable enables checks to be performed against public1_v4 or any other variable that is
#   in the entity for the correct IP.
#
maas_target_alias: public0_v4

#
# ssl_check: This flag indicates if the ssl-related checks and alarms should be deployed.
#
ssl_check: true

#
# dell_check: This flag indicates if the Dell-related hardware monitoring checks and alarms should
#             be deployed.
#
dell_check: false

#
# remote_check: This flag indicates if the remote.http checks and alarms should be deployed.
#
remote_check: true
hp_check: false

#
# lb_name: Defines the entity name of the load balancing device against which the remote MaaS
#          checks and alarms are configured.
#
lb_name: 'unspecified_lb'

#
# maas_scheme: The scheme (http/https) to use when creating remote.http checks.
#
maas_scheme: http

#
# maas_*_scheme: Override the scheme (http/https) for an indivual service.
#
# maas_cinder_scheme: https
# maas_glance_scheme: https
# maas_keystone_scheme: https
# maas_neutron_scheme: https
# maas_nova_scheme: https
maas_horizon_scheme: https
# maas_heat_api_scheme: https
# maas_heat_cfn_scheme: https
# maas_heat_cloudwatch_scheme: https
# maas_swift_proxy_scheme: https

cinder_service_port: 8776
#
# maas_keystone_user: The keystone user to use/create to allow monitoring plugins to query
#                     OpenStack APIs.
#
maas_keystone_user: maas

#
# maas_rabbitmq_user: The rabbitmq user that is created for rabbitmq tests to use.
#
#
maas_rabbitmq_user: maas_user

#
# maas_alarm_local_consecutive_count: The number of consecutive failures before an alert is
#                                     generated for local checks.
#
#   WARNING: Changing this variable affects a customer's SLA, DO NOT change unless you are sure you
#            are sure you know what you're doing!
#
maas_alarm_local_consecutive_count: 3

#
# maas_alarm_remote_consecutive_count: The number of consecutive failures before an alert is
#                                      generate for remote checks.
#
#   WARNING: Changing this variable affects a customer's SLA, DO NOT change unless you are sure you
#            are sure you know what you're doing!
#
maas_alarm_remote_consecutive_count: 1

#
# maas_check_period: The polling interval, defined in seconds
#
#   WARNING: Changing this variable affects a customer's SLA, DO NOT change unless you are sure you
#            are sure you know what you're doing!
#
maas_check_period: 60

#
# maas_check_timeout: Time that will elapse before timeout, defined in seconds. This period must be
#                     less than the maas_check_period.
#
#   WARNING: Changing this variable affects a customer's SLA, DO NOT change unless you are sure you
#            are sure you know what you're doing!
#
maas_check_timeout: 30

#
# maas_monitoring_zones: Specifies the list of data centers (DCs) to poll from for remote
#                        (non-agent) checks.
#
# The default is usually sufficient; for example, if three out of five zones return without failure,
# the check will complete successfully. If for some reason one DC consistently could not perform
# the checks, or if you want to explicitly exclude a DC, set this variable to a list of zones that
# does not include the blocked DC.
#
maas_monitoring_zones:
  - mzdfw
  - mziad
  - mzord
  - mzlon
  - mzhkg

#
# maas_fqdn_extension: Sets the fully-qualified domain name (FQDN) extension that will be appended
#                      to the short names for hosts that are specified in rpc_user_config. This
#                      avoids the need to specify extremely long container names.
#
#   For example, if this variable was not set, a device called 12345-node1.mytestcluster.com would
#   have to be named in openstack_user_config.yml as 12345-node1.mytestcluster.com for MaaS checks
#   to be created correctly. However, if maas_fqdn_extension is set as .mytestcluster.com, the
#   device can be named 12345-node1 in openstack_user_config.yml. This enables shorter container
#   names while still enabling MaaS checks and alarms to be created properly.
#
# maas_fqdn_extension: .example.com
maas_fqdn_extension:

#
# maas_excluded_devices: Specifies devices that will be skipped when creating alarms for disk
#                        utilisation monitoring.
#
# maas_excluded_devices: ['xvde']

#
# maas_filesystem_threshold: Sets the threshold (%) for filesystem monitoring when you are not
#                            specifying specific filesystems.
#
maas_filesystem_warning_threshold: 80.0
maas_filesystem_critical_threshold: 90.0

#
# maas_filesystem_monitors: Explicitly set the filesystems to set up monitors/alerts for.
#
#   NOTE: You can override these in your openstack_user_config.yml per device using
#         "maas_filesystem_overrides".
#
# maas_filesystem_monitors:
#  - filesystem: /
#    warning_threshold: 80.0
#    critical_threshold: 90.0
#  - filesystem: /boot
#    warning_threshold: 80.0
#    critical_threshold: 90.0

# Maas mysql connection thresholds
mysql_connection_warning_threshold: 80
mysql_connection_critical_threshold: 90

# Maas mysql access denied thresholds
# e.g If number of access denied errors inbetween checks
# exceeds 20, the alarm will go into CRITICAL status.
mysql_access_denied_errors_rate_warning_threshold: 10
mysql_access_denied_errors_rate_critical_threshold: 20

# Maas mysql aborted clients rate threshold
# The rate is derived on a per-check basis.
# In other words, this threshold defines how many
# aborted_clients per check are needed to trigger
# an alarm.
mysql_aborted_clients_rate_warning_threshold: 1
mysql_aborted_clients_rate_critical_threshold: 2

# Maas mysql aborted connects rate threshold
# The rate is derived on a per-check basis.
# In other words, this threshold defines how many
# aborted_connects per check are needed to trigger
# an alarm
mysql_aborted_connects_rate_warning_threshold: 1
mysql_aborted_connects_rate_critical_threshold: 2

# Maas mysql open file percentage threshold
mysql_open_files_percentage_warning_threshold: 90
mysql_open_files_percentage_critical_threshold: 95

# Maas InnoDB row lock time avg thresholds, in milliseconds.
innodb_row_lock_time_avg_warning_threshold: 2000
innodb_row_lock_time_avg_critical_threshold: 10000

# cinder-volumes volume group thresholds
cinder_volumes_vg_warning_threshold: 80.0
cinder_volumes_vg_critical_threshold: 90.0
cinder_vg_name: "{{ cinder_backends['lvm']['volume_group'] }}"

# MaaS CPU idle threshold
cpu_idle_percent_avg_threshold: 10.0

# MaaS Memory in use threshold
memory_used_percentage_threshold: 95.0

# Set the threshold for the "Max Channels per Connection" Rabbitmq alarm
rabbitmq_max_channels_per_con_threshold: 10
rabbitmq_fd_used_threshold: 90
rabbitmq_proc_used_threshold: 90
rabbitmq_socket_used_threshold: 90
rabbitmq_queued_messages_excluding_notifications_threshold: 100

# queued messages per check period (default = 60s)
rabbitmq_queue_growth_rate_threshold: 15


# Set the threshold for the "Disk utilisation" MaaS alarms
disk_utilisation_threshold: 90

# nf_conntrack threshold
nf_conntrack_threshold: 90

# net_max_speed has units of Mb/s, set to null for auto discovery
net_max_speed: null
net_rx_pct_warn: 40
net_rx_pct_crit: 60
net_tx_pct_warn: 40
net_tx_pct_crit: 60

# Swift MaaS thresholds
swift_object_quarantine_failed_percentage_threshold: 5.0
swift_object_quarantine_average_threshold: 25.0
swift_object_replication_failure_percentage_threshold: 5.0
swift_object_replication_growth_rate_threshold: 10.0
swift_object_replication_avg_time_threshold: 50.0
swift_account_quarantine_failed_percentage_threshold: 5.0
swift_account_quarantine_average_threshold: 25.0
swift_account_replication_failure_percentage_threshold: 5.0
swift_account_replication_growth_rate_threshold: 10.0
swift_account_replication_avg_time_threshold: 50.0
swift_container_quarantine_failed_percentage_threshold: 5.0
swift_container_quarantine_average_threshold: 25.0
swift_container_replication_failure_percentage_threshold: 5.0
swift_container_replication_growth_rate_threshold: 10.0
swift_container_replication_avg_time_threshold: 50.0
swift_async_pending_failure_percentage_threshold: 5.0
swift_async_pending_average_threshold: 25.0

# cloud level resource thresholds
cloud_resource_warning_memory: 80.0
cloud_resource_critical_memory: 90.0
cloud_resource_warning_vcpus: 80.0
cloud_resource_critical_vcpus: 90.0
cloud_resource_warning_disk_space: 80.0
cloud_resource_critical_disk_space: 90.0
cloud_resource_cpu_allocation_ratio: 2.0
cloud_resource_mem_allocation_ratio: 1.0

# List of checks, by type - variable:
hp_checks_list:
  - { name: "hp-memory", group: "hosts" }
  - { name: "hp-processors", group: "hosts" }
  - { name: "hp-vdisk", group: "hosts" }

dell_checks_list:
  - { name: "openmanage-memory", group: "hosts" }
  - { name: "openmanage-processors", group: "hosts" }
  - { name: "openmanage-vdisk", group: "hosts" }

cpu_memory_checks_list:
  - { name: "cpu_check", group: "hosts" }
  - { name: "memory_check", group: "hosts" }

disk_utilisation_checks_list:
  - { name: "disk_utilisation", group: "hosts" }

ceph_checks_list:
  - { name: "ceph_osd_stats", group: "osds" }
  - { name: "ceph_mon_stats", group: "mons" }
  - { name: "ceph_cluster_stats", group: "mons" }

network_checks_list:
  - { name: "{{ ansible_default_ipv4.interface }}", group: "hosts", max_speed: "{{ net_max_speed }}", rx_pct_warn: "{{ net_rx_pct_warn }}", rx_pct_crit: "{{ net_rx_pct_crit }}", tx_pct_warn: "{{ net_tx_pct_warn }}", tx_pct_crit: "{{ net_tx_pct_crit }}"}

kernel_checks_list:
  - { name: "conntrack_count", group: "hosts" }

openstack_service_local_checks_list:
  - { name: "cinder_api_local_check", group: "cinder_api" }
  - { name: "cinder_scheduler_check", group: "cinder_scheduler" }
  - { name: "glance_api_local_check", group: "glance_api" }
  - { name: "glance_registry_local_check", group: "glance_registry" }
  - { name: "heat_api_local_check", group: "heat_api" }
  - { name: "heat_cfn_api_check", group: "heat_api_cfn" }
  - { name: "heat_cw_api_check", group: "heat_api_cloudwatch" }
  - { name: "horizon_local_check", group: "horizon" }
  - { name: "keystone_api_local_check", group: "keystone" }
  - { name: "neutron_api_local_check", group: "neutron_server" }
  - { name: "neutron_dhcp_agent_check", group: "neutron_dhcp_agent" }
  - { name: "neutron_l3_agent_check", group: "neutron_l3_agent" }
  - { name: "neutron_linuxbridge_agent_check", group: "neutron_linuxbridge_agent" }
  - { name: "neutron_metadata_agent_check", group: "neutron_metadata_agent" }
  - { name: "neutron_metering_agent_check", group: "neutron_metering_agent" }
  - { name: "nova_api_metadata_local_check", group: "nova_api_metadata" }
  - { name: "nova_api_local_check", group: "nova_api_os_compute" }
  - { name: "nova_compute_check", group: "nova_compute" }
  - { name: "nova_cert_check", group: "nova_cert" }
  - { name: "nova_conductor_check", group: "nova_conductor" }
  - { name: "nova_scheduler_check", group: "nova_scheduler" }
  - { name: "nova_consoleauth_check", group: "nova_console" }
  - { name: "nova_spice_console_check", group: "nova_console" }
  - { name: "nova_cloud_stats_check", group: "nova_api_os_compute" }

cinder_vg_checks_list:
  - { name: "cinder_vg_check", group: "cinder_volume", cinder_vg_name: "{{ cinder_vg_name }}" }

#
# cinder_backup_checks_list: A list of checks for the cinder-backup service
#
#   This check was originally part of openstack_service_local_checks_list, but
#   as cinder-backup is enabled/disabled via
#   cinder_service_backup_program_enabled in the os_cinder role we have pulled
#   it out so we can make a separate task conditional on that variable.
#
cinder_backup_checks_list:
  - { name: "cinder_backup_check", group: "cinder_backup" }

swift_checks_list:
  - { name: "swift_object_server_check", group: "swift_obj" }
  - { name: "swift_account_server_check", group: "swift_acc" }
  - { name: "swift_container_server_check", group: "swift_cont" }
  - { name: "swift_proxy_server_check", group: "swift_proxy" }
  - { name: "swift_md5_check", group: "swift_hosts" }
  - { name: "swift_quarantine_check", group: "swift_hosts" }
  - { name: "swift_async_check", group: "swift_hosts" }
  - { name: "swift_object_replication_check", group: "swift_obj" }
  - { name: "swift_account_replication_check", group: "swift_acc" }
  - { name: "swift_container_replication_check", group: "swift_cont" }

openstack_service_remote_checks_list:
  - { name: "lb_api_check_cinder", group: "cinder_api" }
  - { name: "lb_api_check_glance", group: "glance_api" }
  - { name: "lb_api_check_keystone", group: "keystone" }
  - { name: "lb_api_check_neutron", group: "neutron_server" }
  - { name: "lb_api_check_nova", group: "nova_api_os_compute" }
  - { name: "lb_api_check_horizon", group: "horizon" }
  - { name: "lb_api_check_heat_api", group: "heat_api" }
  - { name: "lb_api_check_heat_cfn", group: "heat_api_cfn" }
  - { name: "lb_api_check_heat_cloudwatch", group: "heat_api_cloudwatch" }
  - { name: "lb_api_check_swift_proxy", group: "swift_proxy" }

ssl_cert_checks_list:
  - { name: "lb_ssl_cert_expiry_check", group: "utility"}

infra_service_local_checks_list:
  - { name: "rabbitmq_status", group: "rabbitmq" }
  - { name: "galera_check", group: "galera" }
  - { name: "memcached_status", group: "memcached" }

# Set this to 'false' to set the lb checks against ALL service infra hosts.
# Checks will be setup but disabled on all but host[0] when this is 'true'.
lb_check_on_single_host: true

raxmon_repo_url: "http://stable.packages.cloudmonitoring.rackspace.com/ubuntu-14.04-x86_64"

maas_apt_keys:
  - { url: "https://monitoring.api.rackspacecloud.com/pki/agent/linux.asc", state: "present" }

maas_apt_repos:
  - { repo: "deb {{ raxmon_repo_url }} cloudmonitoring main", state: "present" }

maas_apt_packages:
  - rackspace-monitoring-agent
  - mariadb-client

#
# maas_pip_packages: Packages we need but are not built by openstack-ansible
#
maas_pip_packages:
  - rackspace-monitoring-cli
  - ipaddr
  - swift

#
# maas_pip_dependencies: These are pip packages we depend on, but should already be built in
#                        openstack-ansible
maas_pip_dependencies:
  - cryptography
  - requests
  - lxml
  - python-cinderclient
  - python-glanceclient
  - python-heatclient
  - python-keystoneclient
  - python-neutronclient
  - python-novaclient
  - python-memcached

maas_plugin_dir: /opt/rpc-openstack/maas/plugins/

maas_rpc_scripts_dir: /opt/rpc-openstack/scripts
#
# maas_excluded_checks: List of checks and alarms to exclude from this deploy
#
maas_excluded_checks: []


#
# openrc definitions from OSA
# This is necessary until LP #1537117 is implemented
openrc_os_endpoint_type: internalURL
openrc_insecure: "{{ (keystone_service_adminuri_insecure | bool or keystone_service_internaluri_insecure | bool) | default(false) }}"

#
# Default horizon site name
#
horizon_site_name: "openstack dashboard"

#
# maas_monitor_cinder_backup: This variable determines if the check for the
#                             cinder-backup service should be deployed
#
maas_monitor_cinder_backup: false

---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: local_setup.yml
  vars:
    check_name: cinder_api_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'cinder_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["cinder_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['cinder_api']

- include: local_setup.yml
  vars:
    check_name: cinder_scheduler_check
    check_details: file=cinder_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'cinder_scheduler_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["cinder-scheduler_status"] != 1) { return new AlarmStatus(CRITICAL, "cinder-scheduler down"); }' }
  user: root
  when: >
    inventory_hostname in groups['cinder_scheduler']

- include: local_setup.yml
  vars:
    check_name: cinder_volume_check
    check_details: file=cinder_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'cinder_volume_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["cinder-volume_status"] != 1) { return new AlarmStatus(CRITICAL, "cinder-volume down"); }' }
  user: root
  when: >
    inventory_hostname in groups['cinder_volume']

- include: local_setup.yml
  vars:
    check_name: glance_api_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'glance_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["glance_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['glance_api']

- include: local_setup.yml
  vars:
    check_name: glance_registry_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'glance_registry_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["glance_registry_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['glance_registry']

- include: local_setup.yml
  vars:
    check_name: heat_api_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'heat_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["heat_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['heat_api']

- include: local_setup.yml
  vars:
    check_name: heat_cfn_api_check
    check_details: file=service_api_local_check.py,args=heat_cfn,args={{ ansible_ssh_host }},args=8000
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'heat_cfn_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["heat_cfn_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['heat_api_cfn']

- include: local_setup.yml
  vars:
    check_name: heat_cw_api_check
    check_details: file=service_api_local_check.py,args=heat_cw,args={{ ansible_ssh_host }},args=8003
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'heat_cw_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["heat_cw_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['heat_api_cloudwatch']

- include: local_setup.yml
  vars:
    check_name: horizon_local_check
    check_details: file=horizon_check.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'horizon_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["horizon_local_status"] != 1) { return new AlarmStatus(CRITICAL, "Horizon unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['horizon']

- include: local_setup.yml
  vars:
    check_name: keystone_api_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'keystone_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["keystone_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['keystone']

- include: local_setup.yml
  vars:
    check_name: neutron_api_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'neutron_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["neutron_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['neutron_server']

- include: local_setup.yml
  vars:
    check_name: neutron_dhcp_agent_check
    check_details: file=neutron_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'neutron_dhcp_agent_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["neutron-dhcp-agent_status"] != 1) { return new AlarmStatus(CRITICAL, "neutron-dhcp-agent down"); }' }
  user: root
  when: >
    inventory_hostname in groups['neutron_dhcp_agent']

- include: local_setup.yml
  vars:
    check_name: neutron_l3_agent_check
    check_details: file=neutron_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'neutron_l3_agent_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["neutron-l3-agent_status"] != 1) { return new AlarmStatus(CRITICAL, "neutron-l3-agent down"); }' }
  user: root
  when: >
    inventory_hostname in groups['neutron_l3_agent']

- include: local_setup.yml
  vars:
    check_name: neutron_linuxbridge_agent_check
    check_details: file=neutron_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'neutron_linuxbridge_agent_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["neutron-linuxbridge-agent_status"] != 1) { return new AlarmStatus(CRITICAL, "neutron-linuxbridge-agent down"); }' }
  user: root
  when: >
    inventory_hostname in groups['neutron_linuxbridge_agent']

- include: local_setup.yml
  vars:
    check_name: neutron_metadata_agent_check
    check_details: file=neutron_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'neutron_metadata_agent_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["neutron-metadata-agent_status"] != 1) { return new AlarmStatus(CRITICAL, "neutron-metadata-agent down"); }' }
  user: root
  when: >
    inventory_hostname in groups['neutron_metadata_agent']

- include: local_setup.yml
  vars:
    check_name: neutron_metadata_agent_proxy_check
    check_details: file=neutron_metadata_local_check.py,args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'neutron_metadata_agent_proxy_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["neutron-metadata-agent-proxy_status"] != 1) { return new AlarmStatus(CRITICAL, "neutron-metadata-agent-proxy non-responsive"); }' }
  user: root
  vars_files:
    - "{{ rpc_repo_path }}/playbooks/roles/os_neutron/defaults/main.yml"
  when: >
    inventory_hostname in groups['neutron_metadata_agent']


- include: local_setup.yml
  vars:
    check_name: neutron_metering_agent_check
    check_details: file=neutron_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'neutron_metering_agent_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["neutron-metering-agent_status"] != 1) { return new AlarmStatus(CRITICAL, "neutron-metering-agent down"); }' }
  user: root
  when: >
    inventory_hostname in groups['neutron_metering_agent']

- include: local_setup.yml
  vars:
    check_name: nova_api_metadata_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_api_metadata_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova_api_metadata_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API (metadata) unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_api_metadata']

- include: local_setup.yml
  vars:
    check_name: nova_api_local_check
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API (os-compute) unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_api_os_compute']

- include: local_setup.yml
  vars:
    check_name: nova_compute_check
    check_details: file=nova_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_compute_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova-compute_status"] != 1) { return new AlarmStatus(CRITICAL, "nova-compute down"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_compute']

- include: local_setup.yml
  vars:
    check_name: nova_cert_check
    check_details: file=nova_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_cert_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova-cert_status"] != 1) { return new AlarmStatus(CRITICAL, "nova-cert down"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_cert']

- include: local_setup.yml
  vars:
    check_name: nova_conductor_check
    check_details: file=nova_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_conductor_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova-conductor_status"] != 1) { return new AlarmStatus(CRITICAL, "nova-conductor down"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_conductor']

- include: local_setup.yml
  vars:
    check_name: nova_scheduler_check
    check_details: file=nova_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_scheduler_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova-scheduler_status"] != 1) { return new AlarmStatus(CRITICAL, "nova-scheduler down"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_scheduler']

- include: local_setup.yml
  vars:
    check_name: nova_consoleauth_check
    check_details: file=nova_service_check.py,args=--host,args={{ ansible_nodename }},args={{ internal_vip_address }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_consoleauth_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova-consoleauth_status"] != 1) { return new AlarmStatus(CRITICAL, "nova-consoleauth down"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_console']

- include: local_setup.yml
  vars:
    check_name: nova_spice_console_check
    check_details: file=service_api_local_check.py,args=nova_spice,args={{ ansible_ssh_host }},args=6082,args=--path,args=spice_auto.html
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'nova_spice_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["nova_spice_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "API unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['nova_console']

- include: local_setup.yml
  vars:
    check_name: rabbitmq_status
    check_details: file={{ check_name }}.py,args=-H,args={{ ansible_ssh_host }},args=-n,args={{ inventory_hostname.split('.')[0] }},args=-U,args={{ maas_rabbitmq_user }},args=-p,args={{ maas_rabbitmq_password }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'rabbitmq_disk_free_alarm_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["rabbitmq_disk_free_alarm_status"] != 1) { return new AlarmStatus(CRITICAL, "rabbitmq_disk_free_alarm_status triggered"); }' }
      - { 'name': 'rabbitmq_mem_alarm_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["rabbitmq_mem_alarm_status"] != 1) { return new AlarmStatus(CRITICAL, "rabbitmq_mem_alarm_status triggered"); }' }
      - { 'name': 'rabbitmq_max_channels_per_conn', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["rabbitmq_max_channels_per_conn"] > 10) { return new AlarmStatus(CRITICAL, "Detected RabbitMQ connections with > 10 channels, check RabbitMQ and all Openstack consumers"); }' }
  user: root
  when: >
    inventory_hostname in groups['rabbitmq']

- include: local_setup.yml
  vars:
    check_name: galera_check
    check_details: file={{ check_name }}.py,args=-H,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'wsrep_cluster_size', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["wsrep_cluster_size"] < {{ groups["galera"] | length }}) { return new AlarmStatus(CRITICAL, "Galera cluster size less than expected"); }' }
      - { 'name': 'wsrep_local_state', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["wsrep_local_state_comment"] != "Synced" ) { return new AlarmStatus(CRITICAL, "Galera cluster node not synced"); }' }
  user: root
  when: >
    inventory_hostname in groups['galera']

- include: local_setup.yml
  vars:
    check_name: memcached_status
    check_details: file={{ check_name }}.py,args={{ ansible_ssh_host }}
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    alarms:
      - { 'name': 'memcache_api_local_status', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric["memcache_api_local_status"] != 1) { return new AlarmStatus(CRITICAL, "memcached unavailable"); }' }
  user: root
  when: >
    inventory_hostname in groups['memcached']

- include: local_setup.yml
  vars:
    devices: "[{% for device in ansible_devices.keys()%}{% if device not in maas_excluded_devices|default([]) %}'{{ device }}',{% endif %}{% endfor %}]"
    check_name: disk_utilisation
    check_details: file={{ check_name }}.py
    check_period: "{{ maas_check_period }}"
    check_timeout: "{{ maas_check_timeout }}"
    # TODO (mattt): refactor this code so we can properly create dynamic alarms
    #               without using jinja
    alarms: "[{% for device in devices %}{ 'name': 'percentage_disk_utilisation_{{ device }}', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[\"disk_utilisation_{{ device }}\"] >= 90.0) { return new AlarmStatus(WARNING, \"Disk utilisation for {{ device }} >= 90%\"); }' },{% endfor %}]"
  user: root
  when: >
    inventory_hostname in groups['hosts']
